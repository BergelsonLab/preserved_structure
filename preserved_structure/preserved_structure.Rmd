---
title: "Preserved Structure Across Vector Space Representations"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"
header-includes:
   - \usepackage[utf8]{inputenc}
   - \usepackage[export]{adjustbox}
   
nocite: |
 @macwhinney2000childes

author-information: > 
      \author{{\large \bf Andrei Amatuni, Estelle He, Elika Bergelson} \\ \texttt{\{andrei.amatuni, estelle.he, elika.bergelson\}@duke.edu} \\ 417 Chapel Dr. Durham, NC 27708 USA \\ Department of Psychology and Neuroscience \\ Duke University}

abstract: 
    "Certain concepts, words, and images are intuitively more similar than others (dog vs. cat, dog vs. spoon), though quantifying such similarity is notoriously difficult. Indeed, this kind of computation is likely a critical part of learning the category boundaries for words within a given language. Here, we use a set of 27 items (e.g. 'dog') that are highly common in infants' input, and use both image- and word-based algorithms to independently compute similarity among them. We find three key results. First, the pairwise item similarities derived within image-space and word-space are correlated, suggesting preserved structure among these extremely different representational formats. Second, the closest 'neighbors' for each item, within each space, showed significant overlap (e.g. both found 'egg' as a neighbor of 'apple'). Third, items with the most overlapping neighbors are later-learned by infants and toddlers. We conclude that this approach, which does not rely on human ratings of similarity, may nevertheless reflect stable within-class structure across these two spaces. We speculate that such invariance might aid lexical acquisition, by serving as an informative marker of category boundaries."

keywords:
    "vector space models; semantic similarity; word learning"
    
output: cogsci2016::cogsci_paper
---

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(tidyverse)
library(ggpubr)
library(broom)
library(ggrepel)
library(forcats)
# library(latex2exp)
```

```{r preliminary_data_loading}
animate <- c("puppy", "duck", "elephant", "pig", "monkey", "giraffe",
             "bear", "baby", "fish", "frog", "cow", "dog", "cat")
words27 <-  read_csv("data/pairwise_distances.csv") %>% distinct(word)
combo <- read_csv("data/pairwise_distances.csv") %>%
  unite(pair, X1, word, remove = T) %>% 
  distinct(cos_word,.keep_all = T)
#eb this gets rid of our redundancy issues
wb_prod <- read_csv("data/wordbank_production.csv") %>%  
   mutate(definition = forcats::fct_recode(definition,
    "fish"    = "fish (animal)",
    "water"   = "water (beverage)")) %>% 
  filter(definition%in%words27$word) %>% 
  mutate(animate = ifelse(definition %in% animate, "animate", "inanimate"))

wb_comp <- read_csv("data/wordbank_comprehension.csv") %>%
     mutate(definition = forcats::fct_recode(definition,
    "fish"    = "fish (animal)",
    "water"   = "water (beverage)")) %>% 
  filter(definition%in%words27$word) %>% 
    mutate(animate = ifelse(definition %in% animate, "animate", "inanimate"))
overlap_ratios <- read_csv("data/overlap_table_central.csv") %>% 
  mutate(animate = ifelse(word %in% animate, T, F))
overlap_ratios_random <- read_csv("data/overlap_table_RANDOM.csv")
# fix water picture in img space
neighbor_counts <- read_csv("data/neighbor_counts_central.csv") %>% 
  rename(definition = word)

neighbor_counts_random <- read_csv("data/neighbor_counts_RANDOM.csv") %>% 
  rename(definition = word)

stimuli_counts <- read_csv("python/stimuli_counts.csv")
```


# Introduction
Infants are presented with a challenge to carve the world into distinct lexical entities in the process of learning their first language. They're provided with little supervision while mapping a territory that William James [-@james2013principles] famously dubbed a "great blooming, buzzing confusion". How they determine which aspects of the world to attend to in service of this goal is an area of ongoing research and debate [@mareschal2001categorization]. Relatedly, features of objects and their environments are varyingly informative with regards to object segmentation and category structure. Some researchers have suggested that categorization is along fundamentally perceptual grounds and that only later in development is conceptual knowledge incorporated into these nascent perceptual categories [@quinn2000emergence; @quinn1997reexamination; @quinn2000understanding]. Others suggest that there are in fact two distinct processes at work, such that perceptual categories are computed automatically by the sensory systems, while conceptual categories are independently formed through conscious action [@mandler2000perceptual]. TrÃ¤uble and Pauen [-@trauble2007role] provide evidence of functional information (regarding the animacy of objects) influencing early category judgements. Gelman and Markman [-@gelman1986categories] explicitly set these two sources of category cues against each other (i.e. functional vs. perceptual), and find that preschoolers can override perceptual overlap in reasoning about functional similarity in natural kinds.

The degree to which conceptual and perceptual information are separable in early learning and in adult experts is an important open question. Any model which hopes to explain the mechanics of human categorization must address how potentially disparate information-sources interface in mental representations, and to what degree they interact. Indeed, evidence from human learners suggests they integrate perceptual and linguistic information during categorization and learning [@colunga2005lexicon; @sloutsky2003role; @sloutsky2001much]. Here we take on a deliberately different approach. We separate computations over images and words, and then compare the overlap in the similarity among items that these systems deduce. Using a set of highly familiar and common words and concepts from a large infant corpus, we compare the output of an image-based similarity analysis and a word co-occurrence similarity analysis for these same items. We use algorithms that learn feature representations without hand engineering, purely as a byproduct of their separate training objectives (i.e. natural language processing vs. object recognition). Comparing the representations these algorithms learn provides a window into the structure of visual and semantic forms.

The terminology in this area of research can be challenging. Delineating the differences between words, concepts, and categories in the abstract, and the processes which underlie identifying, understanding, or comparing particular instances of them is not trivial. For present purposes, we stick to concrete, 'basic level' nouns that are early-acquired, since our underlying question concerns how such words are learned. We assume that nouns refer to concepts, which have categorical boundaries (such that cats are not in the 'dog' category), while acknowledging that multiple nouns can refer to a given concept, and different concepts can be called to mind by a given word. We further assume that specific instances of words and specific referents of the concept a word picks out are both used to learn the word's meaning and the concept's category boundaries. We use the term 'item' to refer to the words/concepts we examine. 

Intuitively, word similarity and image similarity are likely to overlap to some degree, since they describe the same underlying entity. Here we explore whether the similarity spaces generated by two disparate algorithms give rise to *similar* similarities among high-frequency items. If they do, it supports the notion of an underlying invariance across representational formats that is capturable by these models. We further examine whether the same "neighboring" items are picked out within these two spaces. One might imagine that the properties that render images similar and words similar are different enough that the overlap will be minimal; in contrast, high overlap would again suggest a true invariance being captured by both word- and image-tokens. Finally, we examine whether having more neighbors within word- and image-space influences early learning.  Given that similarity makes word-learning and category-learning more difficult [@rosch1978cognition; @stager1997infants], we hypothesize that items with more neighbors will be later-learned (i.e. known by fewer children of a given age.)

# Methods
## Items
We analyze 27 high-frequency items from infants' early visual and linguistic input, aggregated as part of SEEDLingS, a project including longitudinal audio and video data of infants' home environments from 6-17 months [@bergelson2016seedlings; @bergelson2016seedlingsdatabrary]. We briefly describe this larger study to relay how these 27 items were chosen. In the larger study, 44 infants were tested every other month (from 6-18 months) on common nouns, using a looking-while-listening eyetracking design in which two images are shown on a screen and one is named. The words for these experiments were chosen by dint of being high frequency or well known across infants in other samples, e.g. the Brent Corpus and WordBank [@brent2001role; @frank2017wordbank], or by being in the top 10 concrete nouns heard in each infant's own home recordings in the preceding two months. 

The images displayed when these words were tested were chosen from a library of prototypical images (e.g. dog) and images of infants' own items, as seen in their home videos (e.g. a given infant's cat, specific bottle, etc.). To enter the current analysis, images had to occur >`r min(stimuli_counts$num_images)` times in this image library of high frequency concrete nouns derived from 264 eyetracking sessions (image counts: M=`r round(mean(stimuli_counts$num_images), 2)`(`r round(sd(stimuli_counts$num_images), 2)`)). These words were heard extremely often over the 528 daylong audio-recordings and 528 hour-long video recordings of these 44 infants (M=`r round(mean(stimuli_counts$bl_freq), 2)`(`r round(sd(stimuli_counts$bl_freq), 2)`)). Thus, the words and images used here provide an ecologically-valid item-set for present modeling purposes.

The images of the 27 items used to derive average category image-vectors were all 960x960 pixel photos of a single object on a gray background. Items correspond to words found on WordBank [@frank2017wordbank], a compilation MacArthur-Bates Communicative Development Inventories, used as a proxy for age of acquisition below [@dale1996lexical].

## Vector Representations
We generate two sets of vector representations for these early-learned items. The first set is taken from a pretrained GloVe representations [@pennington2014glove], a modern distributional semantic vector space model. The second is taken from the final layer activations of a pretrained image recognition model, Google's Inception V3 CNN [@szegedy2016rethinking]. Both of these representations are generally referred to as "embeddings". They map objects from one medium (e.g. images or words) into a metric space where distances between points can be computed and function as similarity measures. 
All code used for generating these vectors and the subsequent analysis can be found on Github.\footnote{\url{https://github.com/BergelsonLab/preserved_structure}}

### Word Vectors
Our word vectors are based on GloVe's instantiation of the distributional hypothesis: co-occurring words share similar meaning [@firth1957synopsis; @harris1954distributional]. Thus, by capturing the covariance of tokens in large corpora, we can capture aspects of semantic structure. We use the set of vectors pretrained by the GloVe authors on the Common Crawl corpus with 42 billion tokens, resulting in 300 dimensional vectors for 1.9 million unique words\footnote{\url{https://nlp.stanford.edu/projects/glove/}}. Such vectors have shown promise in modeling early semantic networks [@amatuni2017semantic]. Thus, in word vector space (hereafter word-space), each of our 27 items is represented as a 300-dimensional vector, with each word assigned a unique point in a common vector space.\footnote{While this corpus is best-suited to our goal of modelling 'how words behave' writ large, we also conducted the analyses below with vectors trained on the North American English CHILDES corpora (MacWhinney, 2000), which is $\sim$4000x smaller. We observe the same qualitative patterns.}

### Image Vectors
The image embeddings are taken from the final layer of activations in a CNN,
<!-- eb: i'm just gonna assume cogsci audience knows what CNNs are -->
whose objective function tunes network parameters in service of object recognition, computing loss in reference to labeled training images. These tuned parameters determine the value of our vectors, transforming the input image signal as it passes through the network. The final layer of this network encodes the most abstract and integrated visual features, serving as the basis for classification into 1000 different classes. The model was trained on the ILSVRC-2012-CLS challenge dataset, which defined the 1000 ImageNet category subset [@ILSVRC15].

Unlike the word vectors we use, different images containing the same type of item will have varying vector representations after passing through the layers of a neural network. This presents a problem in comparing the two forms of representation. Thus, we first define the most prototypical image vector for any given category of object, which will generate our 2048-dimensional representation for each of the 27 items, in image vector space (hereafter image-space).

Given a set of images $S_c$ containing objects belonging to a single category $c$ (e.g. cat, chair), we define our prototypical vector $\hat{x}_c$ of $S_c$ as the generalized median within a representational space $U$. This is the vector with minimal sum of distances between it and all the other members of set $S_c$ in $U$. If $x$ and $y$ are vectors in space $U$, products of images in $S_c$ being passed through a neural network, then $\hat{x}_c = \operatorname*{arg\,min}_{x\in U} \sum_{y\in U} d(x, y)$. We define $d(x, y)$ as the cosine distance measure: $d(x, y) = 1 - \frac{x\cdot y}{\|x\|\|y\|}$


```{r inception_performance, echo=F}
perf <- read_csv("python/classify_performance.csv")
top_1_perf = sum(perf$top_1)/length(perf$top_1)
top_5_perf = sum(perf$top_5)/length(perf$top_5)
```

This is not a distance function in the strict sense, but unlike Euclidean distance, is less susceptible to differences in $L^2$ norm influencing our measure of similarity. Thus in principle, cosine similarity corrects for frequency effects inherent to the training data. To validate our image vectors, we benchmarked classification accuracy, finding that Inception V3 is indeed learning useful representations of these highly child-centric images: the model's top prediction was of the correct item-class `r round(top_1_perf, 2)*100`% of the time; in `r round(top_5_perf, 2)*100`% of cases it was in the top 5. 
Even when incorrect, predictions tended to reflect idiosyncrasies in child-relevant items, e.g. the top guess for a cartoon puppy was "teddy". 


## Comparing spaces 
Having computed our two sets of vectors (i.e. word-space and image-space), we can compare pairwise distances between items, both within a single space and across the two. When comparing across the two spaces, a correlation in pairwise distances implies that inter-object distances have been conserved. For example, if "dog" and "cat" are close together in word space and mutually far apart from "chair" and "table" in that same space, maintaining this relationship for all pairwise distances in the \textit{other} vector space means that the global inter-object structure is preserved across this mapping. This is despite being in strikingly different spaces, both in terms of dimensionality (words:300, images:2048) and by virtue of using completely different algorithms and inputs to establish the vector representations for items. So while their absolute locations might have been transformed, this correlation (and related computations) would be a measure of the \textit{degree of invariance} in their positioning relative to each other. 

```{r img_word_corrs, echo=F}
pairwise_corr <- cor.test(combo$cos_img, combo$cos_word, conf.int=T) %>% tidy()

pairwise_corr_string <- sprintf("$R = %0.2f$, $p < %1.2g$", pairwise_corr$estimate, pairwise_corr$p.value)
```

```{r overlap_stats, echo = F, results = "hide"}

shapiro.test(overlap_ratios$overlap_ratio)#almost normal
overlap_wilcox <- wilcox.test(overlap_ratios$overlap_ratio, conf.int=T)# significantly different from chance
#even with correction, both animate and animate overlaps>0, not different from each other
# wilcox.test(subset(overlap_ratios, animate==F)$overlap_ratio)
# wilcox.test(subset(overlap_ratios, animate==T)$overlap_ratio)
# wilcox.test(subset(overlap_ratios, animate==T)$overlap_ratio,
#             subset(overlap_ratios, animate==F)$overlap_ratio)

shapiro.test(overlap_ratios_random$overlap_ratio)

overlap_wilcox_random <- wilcox.test(overlap_ratios_random$overlap_ratio, conf.int=T)
# overlap_wilcox
# overlap_wilcox_random
# 
#eb: this one is key: it's significantly smaller with random (but needs to be a paired test)
overlap_wilcox_compwithrandom<-wilcox.test(overlap_ratios$overlap_ratio, overlap_ratios_random$overlap_ratio, conf.int=T, paired=T)

```


```{r pairwise-corr, echo = F, fig.cap = cap, fig.height=2.4, fig.width=3.1}
ggplot(combo, aes(cos_word, cos_img))+
  geom_point(size=3, shape =1)+
  geom_smooth(method="lm", aes(group=1), show.legend=F, fill ="red", alpha = .7)+
  geom_smooth(method="lm", aes(group=1), se=F)+ # this second line is to trick ggplot into not putting the gray fill in the boxes in the legend (coming from the standard error in the first line)
  theme_bw()+
  xlab("Pairwise Word Distance")+
  ylab("Pairwise Image Distance")+
  xlim(0.2,0.80)+
  ylim(0.2,0.7)+
  theme(legend.position="bottom", 
        legend.title = element_blank(), 
        legend.text = element_text(size=7), 
        legend.key.width = unit(0.4, "cm"),
        legend.key = element_rect(fill = 'white', size = 0.1)
        )

cap <- sprintf("Relative cosine distance between items in word-space (x-axis) and image-space (y-axis), for each item pair. Fitted line reflects linear fit with SE ($R = %0.2f$, $p < .001$).", pairwise_corr$estimate, pairwise_corr$p.value)
```

# Results
To test whether image- and word-based similarity converged, we conducted several analyses. First, we tested whether the pairwise cosine distances for all items in word-space correlated with those same pairwise distances in image-space (see Figure \ref{fig:pairwise-corr}). We find a significant correlation among the 351 pairs of distances (`r pairwise_corr_string`)\footnote{since distances are identical for cat-dog and dog-cat, and since we omit an item's distance to itself (0), there are (27*27-27)/2) pairs of distances. For simplicity, we report Pearson's R and plot linear fit on Fig. 1; non-parametric correlations (e.g. Spearman's $\rho$) reveal the same pattern.}.

Next, we examined the degree to which our set of 27 words shared overlapping 'neighbors' in the two vector spaces (see Figure \ref{fig:overlap-table}). 
<!-- eb: you mean table 1 right? -->
We defined neighbor by first determining the mean similarity distance between each item and the 26 other items. Any items whose distance to this target had a z-score of less than -1 was considered a neighbor. Within word-space, items had on average `r round(mean(neighbor_counts$word_count), 2)` neighbors ($SD=`r round(sd(neighbor_counts$word_count), 2)`$ , $R=`r min(neighbor_counts$word_count)`-`r max(neighbor_counts$word_count)`)$. Within image-space, items had 2.51 neighbors ($SD=`r round(sd(neighbor_counts$image_count), 2)`$, $R=`r min(neighbor_counts$image_count)`-`r max(neighbor_counts$image_count)`$).

We next tested whether both spaces picked out overlapping neighbors (e.g. whether the neighbor of 'cat' in image-space overlapped with the neighbors of 'cat' in word-space. The majority of items have at least 1 neighbor which is shared across representational spaces. We quantified this through overlap ratios: (# overlap)/(# neighbors).  Overlap was significantly greater than 0 ($M=`r round(mean(overlap_ratios$overlap_ratio), 3)`$, $SD=`r round(sd(overlap_ratios$overlap_ratio), 2)`$, $p < 0.001$ by Wilcoxon test). This complements the correlational analysis, showing not only do the distances for any given pair tend to have similar values in image- and word-space, but that the *most* similar words/images (i.e. each item's neighbors) were also consistent across these spaces.



## Connecting with Learnability
While some degree of convergence across image and word spaces is expected given that these are two different manifestations of the same underlying concept/word/item, we next queried whether this invariance related to learnability. We hypothesized that words with more overlapping neighbors would be harder for children to learn, since both the visual and linguistic spaces they occur in are more 'cluttered.' To test this, we looked at the relative rates of acquisition of these items in WordBank [@frank2017wordbank], using the 6945 children's data from English. Since we did not have clear predictions about specific ages, or of tradeoffs between comprehension and production, we used both. I.e., we used comprehension norms (from MCDI-Words and Gestures, averaging over 8-18 months) and production norms (from MCDI-Words and Sentences, averaging over 16-30 months). 

```{r overlap-aoa, echo=F}
wb_prod_long <- wb_prod %>% 
  gather(`16`:`30`, value = 'mean_prop_prod', key = "month")
wb_comp_long <- wb_comp %>% 
  gather(`8`:`18`, value = 'mean_prop_comp', key = "month")
wb_prod_long_allmonths <- wb_prod_long %>% 
  group_by(definition, animate) %>% 
  summarise(overall_prop_prod = mean(mean_prop_prod)) %>% 
  left_join(neighbor_counts) %>% 
  mutate(totalneighbors = (image_count+word_count)-overlap_count,
         overlapratio = overlap_count/totalneighbors)

wb_comp_long_allmonths <- wb_comp_long %>% 
  group_by(definition, animate) %>% 
  summarise(overall_prop_comp = mean(mean_prop_comp)) %>% 
  left_join(neighbor_counts) %>% 
  mutate(totalneighbors = (image_count+word_count)-overlap_count,
         overlapratio = overlap_count/totalneighbors)

prod_overlap_corr <- cor.test(wb_prod_long_allmonths$overall_prop_prod, wb_prod_long_allmonths$overlap_count, conf.int=T) %>% tidy()
comp_overlap_corr <- cor.test(wb_comp_long_allmonths$overall_prop_comp, wb_comp_long_allmonths$overlap_count, conf.int=T) %>% tidy()

wb_all<- wb_comp_long_allmonths %>% 
  left_join(wb_prod_long_allmonths) %>% 
  gather(c(overall_prop_comp, overall_prop_prod), value = prop_kids, key = comp_prod ) %>% 
  mutate(comp_prod = fct_recode(comp_prod,
    "production" = "overall_prop_prod",
    "comprehension" = "overall_prop_comp"
  ))

write.csv(wb_all, "overlap_correlations.csv")

# cor.test(wb_all$overlap_count, wb_all$prop_kids) # correlation
```

```{r overlap-aoa-graphs, echo=F, fig.cap = cap, fig.width = 3.5, fig.height=3}

ggplot(wb_all, aes(overlap_count,prop_kids, color = comp_prod))+
  geom_point(shape=1)+
  geom_text_repel(aes(label = definition), size=2.4, force=2)+
  facet_wrap(~comp_prod, scales = "free_y")+
  stat_smooth(method = "lm")+
  theme_bw(base_size = 10)+
  theme(axis.title=element_text(size=7))+
  guides(colour = "none")+
  xlab("# of overlapping neighbors")+
  ylab("prop. word knowledge")

cap <- "Proportion of children in WordBank reported to understand (left, 8-18mo.average) or produce (right, 16-30mo. average) the 27 items, as a function of number of overlapping (image and word) neighbors. Lines indicates linear fit with SE CIs (both R$>$-.45, p$<$.05)."
```




```{r overlap-aoa-random, echo=F}
wb_prod_long <- wb_prod %>% 
  gather(`16`:`30`, value = 'mean_prop_prod', key = "month")
wb_comp_long <- wb_comp %>% 
  gather(`8`:`18`, value = 'mean_prop_comp', key = "month")
wb_prod_long_allmonths_random <- wb_prod_long %>% 
  group_by(definition, animate) %>% 
  summarise(overall_prop_prod = mean(mean_prop_prod)) %>% 
  left_join(neighbor_counts_random) %>% 
  mutate(totalneighbors = (image_count+word_count)-overlap_count,
         overlapratio = overlap_count/totalneighbors)

wb_comp_long_allmonths_random <- wb_comp_long %>% 
  group_by(definition, animate) %>% 
  summarise(overall_prop_comp = mean(mean_prop_comp)) %>% 
  left_join(neighbor_counts_random) %>% 
  mutate(totalneighbors = (image_count+word_count)-overlap_count,
         overlapratio = overlap_count/totalneighbors)

prod_overlap_corr_random <- cor.test(wb_prod_long_allmonths_random$overall_prop_prod, wb_prod_long_allmonths_random$overlap_count, conf.int=T) %>% tidy()
comp_overlap_corr_random <- cor.test(wb_comp_long_allmonths_random$overall_prop_comp, wb_comp_long_allmonths_random$overlap_count, conf.int=T) %>% tidy()

wb_all_random<- wb_comp_long_allmonths_random %>% 
  left_join(wb_prod_long_allmonths_random) %>% 
  gather(c(overall_prop_comp, overall_prop_prod), value = prop_kids, key = comp_prod ) %>% 
  mutate(comp_prod = fct_recode(comp_prod,
    "production" = "overall_prop_prod",
    "comprehension" = "overall_prop_comp"
  ))


# cor.test(wb_all_random$overlap_count, wb_all_random$prop_kids) # no correlation with random vecs
# cor.test(wb_all$overlap_count, wb_all$prop_kids) # correlation
```

```{r overlap-aoa-graphs-random, echo=F, fig.cap = cap, fig.width = 3.5, fig.height=3, eval=F}

# for random vector, no relationship between overlap and learnability

ggplot(wb_all_random, aes(overlap_count,prop_kids, color = comp_prod))+
  geom_point(shape=1)+
  geom_text_repel(aes(label = definition), size=2.4, force=2)+
  facet_wrap(~comp_prod, scales = "free_y")+
  stat_smooth(method = "lm")+
  theme_bw(base_size = 10)+
  theme(axis.title=element_text(size=7))+
  guides(colour = "none")+
  xlab("# of overlapping neighbors")+
  ylab("prop. word knowledge")

```

We found that the number of overlapping neighbors a given word had was negatively correlated with the proportion of children who were reported to understand ($R=`r round(comp_overlap_corr$estimate, 2)`$, $p = `r round(comp_overlap_corr$p.value, 3)`$) and produce the word ($R=`r round(prod_overlap_corr$estimate, 2)`$, $p = `r round(prod_overlap_corr$p.value, 3)`$); see Figure \ref{fig:overlap-aoa-graphs}. That is, words with more overlapping neighbors are later-learned (i.e. known by fewer children) than words with fewer overlapping neighbors. To test whether this was specific to overlap, we examined the number of image-only and word-only neighbors (see Figure \ref{fig:overlap-table})), but found no correlations with word knowledge (all $p > .05$). 

Analyses using randomly generated vectors of identical dimensionality showed no preserved structure across spaces, a significantly smaller overlap ratio  ($M$ = `r round(mean(overlap_ratios_random$overlap_ratio), 3)`, $SD=`r round(sd(overlap_ratios_random$overlap_ratio), 3)`$,  $p = 0.006$ by Wilcoxon test), and critically, no correlations with learning. 
<!-- eb: see my comment above: this is smoothing over the part where the overlap in random is non-zero and saying well it's smaller than in the real case. we do want to think about why the random overlap is different from chance at all though... -->


```{r overlap-table, echo=FALSE, out.width='100%', fig.cap = cap}
knitr::include_graphics('figs/overlap_table.pdf')
cap <- "Neighbors in image- and word-space. Overlapping neighbors are in bold and red; italicised words are image-neighbors only, underlined words are word-neighbors only. Overlap ratio reflects shared over total neighbors."
```



# Discussion
The results above revealed a notable correspondence between representations learned by two different algorithms operating over inputs in two fundamentally different encodings (i.e. visual and linguistic). We find that not only are the relative distances among these 27 common, early-learned items correlated across word- and image-space, but that even at the item-level, the closest words (i.e. neighbors) in both spaces overlap as well. Moreover, words corresponding to items with more neighbors were reportedly less well known by young children. Notably, the common ground between these representations is the real life concepts they both aim to model. This is particularly noteworthy given the dimensionality of our feature spaces, and that these algorithms were placed under no pressure to find homologous representations. That said, we do not suggest that these algorithms learn representations the way children do, though we note that CNN architectures were originally inspired by primary visual cortex [@fukushima1982neocognitron] and GloVe has recently been used to decode semantic representations from brain activity [@pereira2018toward]. To be clear, none of the corpora used to train the models here are meant to represent a *given* child's input or representations. They are meant to study structure inherent *in the learning data*, namely the degree to which visual and linguistic information is purely separable. 

The notion that we can make inferences about one aspect of an object given another aspect is not surprising or controversial. Rather than considering multiple dimensions at once as real learners must, here we show that even with the experiences parcelled out separately into visual and linguistic spaces, 'similarity' is conserved to some degree. That said, a limitation of the current work is that the image vectors are trained on images in context; while in real life images occur with informative context, extending this approach to decontextualized images using unsupervised algorithms would provide a cleaner demonstration of 'purely' visual similarity; we save this for future work. Relatedly, while we used common infant-oriented items, a wider item-space (less skewed to animals for instance) would fruitfully extend this research.

Through what metrics can a learning algorithm, or indeed a human, establish gradations of likeness? Are these necessarily the same metrics which form the basis of category boundaries? These are fundamental questions in the field [@shepard1970second; @tversky1977features; @kemp2005generative; @hahn2003similarity; @edelman1998representation]. While our current results are not sufficient to support a specific mechanism, it suggests a special role for invariance, given that the unifying thread between our algorithms and inputs are the common objects they represent. Underneath the diversity of visual statistics and token distributions lie stable entities in the world which give rise to regularity across measurements at different vantage points (i.e. modalities), an idea dating back to Helmholtz [-@helmholtz1878facts]. Recent findings examining the mechanics of generalization in DNNs lend modern information theoretic support to this notion [@shwartz2017opening; @achille2017emergence]. That said, many things that 'go together' are not visually similar, but rather have hierarchical, functional, or associative relations (e.g. carrot/vegetable, skateboard/boat, carrot/bunny, respectively); we leave this to future work.

In principle, one would expect that words with greater invariance across different representational dimensions would be learned earlier, since such representations are likely easier to make categorical inferences over. Indeed, while many words lack visual correlates, e.g. grammatical markers or unobservables [@gleitman2005hard], words with less consistent visual features are generally learned later [@dale1996lexical; @bergelson2013acquisition]. This is in contrast to the more helpful scenario where, for example, visibly round objects occur with 'roll'; indeed such correlated perceptual and linguistic cues aid the child learner [@yoshida2005linguistic]. 

Our WordBank-based analysis speaks to this, highlighting that for these concrete nouns, when the space is cluttered along both visual and linguistic dimensions, learning is slower. Notably, we find no effect of word- or image-only neighbors, suggesting that the overlap-neighbor effect may indeed be due to the (perhaps more noticeable) âclutterâ across spaces. Such an account is in keeping with research that finds that for displays of semantically-similar items, word comprehension is reduced [@bergelson2017nature; @arias2010effects]. Similar feature-space cluttering effects have been a standard in the visual search literature, where target-to-distractor similarity reduces speed and accuracy of search [@treisman1988feature; @duncan1989visual]. 
Interestingly, when learning the structure of new objects, adults learning Chinese characters perform better in visual search when they are trained with characters that force attention to the points of confluence between features [@popov2017target]; perhaps infants do the same. That said, while concrete nouns are an appropriate target for these current analyses given their demonstrably early age of acquisition [@dale1996lexical], further work with more abstract words (nouns and beyond) is a clear next step. 

The results here provide in-principle proof that vector space models of words and images can be fruitfully combined and linked to early language and concept learning. Our approach could readily be extended to examine learning-relevant properties like animacy, shape, and color (e.g. Frank, Vul, & Johnson [-@frank2009development], Landau, Smith, & Jones [-@landau1992syntactic]). Along these lines, in an exploratory analyses with these items we find that splitting item-pairs into animate, inanimate, and mixed categories suggests that the image- and word-based correlation is particularly strong for the inanimate items, though with only 27 items, further conclusions are as-yet unwarranted. However, one can imagine that in a larger database of children's visual and linguistic experiences, tests of overlapping similarity and relative degrees of within-class structure conservation may provide informative leverage for predicting age of acquisition across the early vocabulary.

# Conclusion
We find evidence of links between visual and linguistic features learned by two distinct machine learning algorithms which operate over drastically different inputs, and are trained in the service of unrelated ends. These links suggest conserved structure between these two separable information sources (i.e. images and words). Indeed, it seems that not only do these algorithms converge on which items are 'closer' in similarity within a group of oft-heard and seen concrete nouns, but that children are sensitive to these overlapping cross-word relationships as well. The process that created the word- and image-spaces we examine here is certainly not meant to be cognitively plausible. Nevertheless, our results suggest that this vector-space approach can be tied to language acquisition, and provides promising new avenues for uncovering cross-representational influences on early word and concept learning.

# Acknowledgements

We thank the BLAB, Eric Bigelow, & NIH DP5-OD019812.

# References 


```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
